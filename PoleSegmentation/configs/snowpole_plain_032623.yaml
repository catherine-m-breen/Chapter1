# training
conf_id: snowpole_plain_032623
algorithm: Plain
num_iters: 10000 #30000
log_interval: 2 ##cat edit: updated to 2 from 10, because it needs to be smaller than batch size
parallel: 0


# data
# will need to update with GPU settings
dataset_root: /Users/catherinebreen/Documents/Chapter1/segmentationModel/sample/ ## update path when get on GPU
dataset_name: SNOWPOLES
num_classes: 2 #
batch_size: 20 # will update with GPU, works with 4 on local
num_workers: 4 #64, works with 3 on local 
comet_api: "crD0w5pAk59gNUJ88yfNuMo5F" ## update this if changing to different comet set-up 

# model
model_name: DeepLabV3_ResNet50
num_layers: 50
output_stride: 16
weights_init: ImageNet

# optim
## feature
lr_feature: 0.001
momentum_feature: 0.9
weight_decay_feature: 0.0004
## classifier
lr_classifier: 0.01
momentum_classifier: 0.9
weight_decay_classifier: 0.0004
## lr_scheduler
step_size: 10000
gamma: 0.1
